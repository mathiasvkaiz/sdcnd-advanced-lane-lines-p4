{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import collections\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_camera_calibration = './camera_cal/'\n",
    "path_test_images = './test_images/'\n",
    "path_ouput_images = './output_images/'\n",
    "\n",
    "pickle_file = 'calibration_pickle.p'\n",
    "input_video = 'project_video.mp4'\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "obj_points = [] # 3d points in real world space\n",
    "img_points = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images_list = glob.glob(path_camera_calibration + 'calibration*.jpg')\n",
    "test_images_list = glob.glob(path_test_images + 'test*.jpg')\n",
    "\n",
    "chessboard_images = []\n",
    "undistorted_images = []\n",
    "\n",
    "# dictionary for creating binary file for calibration data\n",
    "dist_pickle = {}\n",
    "\n",
    "# mask values\n",
    "top_left = [580, 450]\n",
    "top_right = [720, 450]\n",
    "bottom_left = [190, 720]\n",
    "bottom_right = [1190, 720]\n",
    "\n",
    "proj_top_left = [320, 0]\n",
    "proj_top_right = [1000, 0]\n",
    "proj_bottom_left = [320, 720]\n",
    "proj_bottom_right = [1000, 720]\n",
    "\n",
    "# check for camera calibration directory\n",
    "if not os.path.exists(path_camera_calibration):\n",
    "    os.makedirs(path_camera_calibration)\n",
    "    \n",
    "# check for test images directory\n",
    "if not os.path.exists(path_test_images):\n",
    "    os.makedirs(path_test_images)\n",
    "\n",
    "# check for output images directory\n",
    "if not os.path.exists(path_ouput_images):\n",
    "    os.makedirs(path_ouput_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output_file_path(filename):\n",
    "    '''creates output path for images and returns it'''\n",
    "    return path_ouput_images + filename + '.jpg'\n",
    "\n",
    "def save_output_file(img, filename):\n",
    "    '''saves the image as file'''\n",
    "    cv2.imwrite(get_output_file_path(filename), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dimensions = (9, 6)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "obj_p = np.zeros((6*9, 3), np.float32)\n",
    "obj_p[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images_list:\n",
    "    # Read each image\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, dimensions, None)\n",
    "\n",
    "    # If corners are found, add object points, image points and image to images array\n",
    "    if ret == True:\n",
    "        obj_points.append(obj_p)\n",
    "        img_points.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, dimensions, corners, ret)\n",
    "        chessboard_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save output image\n",
    "save_output_file(chessboard_images[0], 'camera_calibration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save points to pickle file for later use\n",
    "dist_pickle['obj_points'] = obj_points\n",
    "dist_pickle['img_points'] = img_points\n",
    "pickle.dump(dist_pickle, open(path_camera_calibration + pickle_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction for Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the saved points and points from pickle file for usage\n",
    "dist_pickle = pickle.load(open(path_camera_calibration + pickle_file, 'rb'))\n",
    "obj_points = dist_pickle['obj_points']\n",
    "img_points = dist_pickle['img_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibration_undistort(img, obj_points, img_points):\n",
    "    '''performs the camera calibration, image distortion correction and \n",
    "    returns the undistorted image'''\n",
    "    \n",
    "    # defined image size\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # calibrate camera and return parameters \n",
    "    retval, camera_matrix, dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, img_size, None, None)\n",
    "    \n",
    "    # undistrot image based on calibration parameters\n",
    "    undist = cv2.undistort(img, camera_matrix, dist_coeffs, None, camera_matrix)\n",
    "    \n",
    "    # save data in pickle\n",
    "    dist_pickle['mtx'] = camera_matrix\n",
    "    dist_pickle['dist'] = dist_coeffs\n",
    "    \n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test calibration and distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images_list = glob.glob(path_test_images + 'test*.jpg')\n",
    "undistorted_images = []\n",
    "\n",
    "# read in images and append to images\n",
    "for fname in test_images_list:\n",
    "    # Read each image\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    # Undistort the image\n",
    "    dst = calibration_undistort(img, obj_points, img_points)\n",
    "    \n",
    "    # append to list\n",
    "    undistorted_images.append(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save output image\n",
    "save_output_file(undistorted_images[0], 'raw_undistorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def undistort(img, obj_points, img_points):\n",
    "    '''performs the image distortion correction and \n",
    "    returns the undistorted image'''\n",
    "    \n",
    "    return calibration_undistort(img, obj_points, img_points)\n",
    "\n",
    "\n",
    "def combined_binary(img, hls_thresh=(90, 255), sx_thresh=(20, 100), rgb_thresh = (200, 255)):\n",
    "    '''performs several steps like channel selection\n",
    "    sobel operators and color thresholding for creating binary image'''\n",
    "    \n",
    "    r_channel = image[:,:,0]\n",
    "    g_channel = image[:,:,1]\n",
    "    b_channel = image[:,:,2]\n",
    "    \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= hls_thresh[0]) & (s_channel <= hls_thresh[1])] = 1\n",
    "    \n",
    "    l_binary = np.zeros_like(s_channel)\n",
    "    l_binary[(l_channel >= hls_thresh[0]) & (l_channel <= hls_thresh[1])] = 1\n",
    "    \n",
    "    r_binary = np.zeros_like(r_channel)\n",
    "    r_binary[(r_channel > rgb_thresh[0]) & (r_channel <= rgb_thresh[1])] = 1\n",
    "    \n",
    "    g_binary = np.zeros_like(g_channel)\n",
    "    g_binary[(g_channel > rgb_thresh[0]) & (g_channel <= rgb_thresh[1])] = 1\n",
    "\n",
    "    # Stack each channel to view their individual contributions in green and blue respectively\n",
    "    # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "    #color_binary = np.dstack(( r_binary, sxbinary, s_binary)) * 255\n",
    "    \n",
    "    # Combine the binary thresholds\n",
    "    # (S&L) | (R&G) | sx\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[((s_binary == 1) & (l_binary == 1)) | ((r_binary == 1) & (g_binary == 1)) | (sxbinary == 1)] = 1\n",
    "    \n",
    "    \n",
    "    return combined_binary\n",
    "\n",
    "def region_of_interest(img, vertices=None):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    \n",
    "    if vertices == None:\n",
    "#         vertices = np.array([[(0, image.shape[0]),\n",
    "#                           (x_axis_mask_left, y_axis_mask), \n",
    "#                           (x_axis_mask_right, y_axis_mask), \n",
    "#                           (image.shape[1], image.shape[0])]\n",
    "#                         ], dtype=np.int32)\n",
    "        \n",
    "        \n",
    "        vertices = np.array([[bottom_left,\n",
    "                          top_left, \n",
    "                          top_right, \n",
    "                          bottom_right]\n",
    "                        ], dtype=np.int32)\n",
    "    \n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def warp(img):\n",
    "    '''Define calibration box in source (original) and destination (desired or warped) coordinates'''\n",
    "    \n",
    "    # get image size\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Four source coordinates\n",
    "    src = np.float32(\n",
    "        [bottom_left,\n",
    "         top_left,\n",
    "         top_right,\n",
    "         bottom_right])    \n",
    "    \n",
    "    \n",
    "    # Four desired coordinates\n",
    "    dst = np.float32(\n",
    "        [proj_bottom_left,\n",
    "         proj_top_left,\n",
    "         proj_top_right,\n",
    "         proj_bottom_right])\n",
    "\n",
    "    # Compute the perspective transform, M\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    # Could compute the inverse also by swapping the input parameters\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    # Create warped image - uses linera interpolation\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped, Minv\n",
    "\n",
    "\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(image, save_ouput_file=False):\n",
    "    '''perfomrs pipeline on input image'''\n",
    "    \n",
    "    # undistorted image\n",
    "    undistorted = undistort(image, obj_points, img_points)\n",
    "    if save_ouput_file==True:\n",
    "        # save output image\n",
    "        save_output_file(undistorted, 'pip_raw_undistorted')\n",
    "        print(\"Undistorted\")\n",
    "        plt.imshow(undistorted)\n",
    "        plt.show()\n",
    "        \n",
    "    # Show masked image for check\n",
    "    masked_image = region_of_interest(image)\n",
    "    if save_ouput_file==True:\n",
    "        # save output image\n",
    "        save_output_file(masked_image, 'pip_masked')\n",
    "        print(\"Masked\")\n",
    "        plt.imshow(masked_image)\n",
    "        plt.show()\n",
    "        \n",
    "    # binary image    \n",
    "    binary = combined_binary(undistorted)\n",
    "    if save_ouput_file==True:\n",
    "        # save output image\n",
    "        save_output_file(binary, 'pip_binary')\n",
    "        print(\"Binary\")\n",
    "        plt.imshow(binary, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "    # warped image\n",
    "    warped, Minv = warp(binary)\n",
    "    if save_ouput_file==True:\n",
    "        # save output image\n",
    "        save_output_file(warped, 'pip_warped')\n",
    "        print(\"Warped\")\n",
    "        plt.imshow(warped, cmap='gray')\n",
    "        plt.show()\n",
    "    \n",
    "    output = []\n",
    "\n",
    "    # Onl the first pipline should save output images\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in image and apply pipeline on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(path_test_images + 'test1.jpg') \n",
    "print('Original')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "output = pipeline(image, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in video and apply pipeline on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory = 'test_videos_output'\n",
    "# if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "# white_output = 'test_videos_output/output.mp4'\n",
    "# ## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "# ## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "# ## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "# ## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "# ##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "# clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "# white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "# %time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
